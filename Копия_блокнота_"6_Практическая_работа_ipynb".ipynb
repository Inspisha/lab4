{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4Xl9TmXcY-sX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inspisha/lab4/blob/master/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%226_%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'gkdkjhg'\n",
        "\n",
        "s_list = []\n",
        "\n",
        "for ss in s:\n",
        "  s_list.append(ss)"
      ],
      "metadata": {
        "id": "UFmRyMOU_IPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PnR7I_c_cLp",
        "outputId": "b2db2006-01a0-4043-ddd1-eb7e9af1167e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['g', 'k', 'd', 'k', 'j', 'h', 'g']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_list_2 = [ss + '1' for ss in s]"
      ],
      "metadata": {
        "id": "UAC0SiiQ_fDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_list_2"
      ],
      "metadata": {
        "id": "xdogESxA_vMw",
        "outputId": "a87e3524-0d69-4962-c660-06f16cb51332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['g1', 'k1', 'd1', 'k1', 'j1', 'h1', 'g1']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируйте библиотеку spacy. Загрузите анализатор для английского языка."
      ],
      "metadata": {
        "id": "QTeQrfm4uU3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "4-PrZvCXmSRN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 1.** Напишите функцию, которая принимает текст в формате строки в качестве аргумента и возвращает список токенов.\n",
        "\n"
      ],
      "metadata": {
        "id": "wuQRsR1iWz5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "McEW8vlym6C5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 2.** Напишите функцию, которая принимает **список токенов** в качестве аргумента и возвращает **список лемм** для каждого токена в тексте."
      ],
      "metadata": {
        "id": "Uy9x4h8mUf7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\"Carole is an aeroplane pilot.\"\n",
        "        \"She usually works during the week and has weekends off, but she sometimes works Saturdays or Sundays.\"\n",
        "        \"When Carol has to work, her day usually starts very early in the morning.\"\n",
        "        \"She wakes up at 4 a.m. and gets ready for work. She has a shower and gets dressed.\"\n",
        "         \"She wears a uniform. At 4.30, Carole has cereal with milk and drinks a large coffee.\"\n",
        "          \"After that, she packs her flight bag for the day.\")"
      ],
      "metadata": {
        "id": "sFm-GzuHUfbn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc= nlp(text)"
      ],
      "metadata": {
        "id": "XzZOxTHvJ_QI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type (doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asVmv5EMKiVT",
        "outputId": "63c50d10-5c08-44e0-8b4b-bbda2811e8a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXVQAORCMsiH",
        "outputId": "0eb2bb56-f845-473d-e251-b44fb42c665b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Carole is an aeroplane pilot.She usually works during the week and has weekends off, but she sometimes works Saturdays or Sundays.When Carol has to work, her day usually starts very early in the morning.She wakes up at 4 a.m. and gets ready for work. She has a shower and gets dressed.She wears a uniform. At 4.30, Carole has cereal with milk and drinks a large coffee.After that, she packs her flight bag for the day."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 3.** Напишите функцию, которая принимает слово (токен) в качестве аргумента и возвращает его **часть речи**."
      ],
      "metadata": {
        "id": "e1scII2mYG88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print (token.text,end='\\t')\n",
        "  print(token.pos_)\n"
      ],
      "metadata": {
        "id": "xPTppZdvaiBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ddec55-5f68-4615-9883-59bf8ecba3d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carole\tPROPN\n",
            "is\tAUX\n",
            "an\tDET\n",
            "aeroplane\tNOUN\n",
            "pilot\tNOUN\n",
            ".\tPUNCT\n",
            "She\tPRON\n",
            "usually\tADV\n",
            "works\tVERB\n",
            "during\tADP\n",
            "the\tDET\n",
            "week\tNOUN\n",
            "and\tCCONJ\n",
            "has\tVERB\n",
            "weekends\tNOUN\n",
            "off\tADP\n",
            ",\tPUNCT\n",
            "but\tCCONJ\n",
            "she\tPRON\n",
            "sometimes\tADV\n",
            "works\tVERB\n",
            "Saturdays\tPROPN\n",
            "or\tCCONJ\n",
            "Sundays\tPROPN\n",
            ".\tPUNCT\n",
            "When\tSCONJ\n",
            "Carol\tPROPN\n",
            "has\tVERB\n",
            "to\tPART\n",
            "work\tVERB\n",
            ",\tPUNCT\n",
            "her\tPRON\n",
            "day\tNOUN\n",
            "usually\tADV\n",
            "starts\tVERB\n",
            "very\tADV\n",
            "early\tADV\n",
            "in\tADP\n",
            "the\tDET\n",
            "morning\tNOUN\n",
            ".\tPUNCT\n",
            "She\tPRON\n",
            "wakes\tVERB\n",
            "up\tADP\n",
            "at\tADP\n",
            "4\tNUM\n",
            "a.m.\tNOUN\n",
            "and\tCCONJ\n",
            "gets\tVERB\n",
            "ready\tADJ\n",
            "for\tADP\n",
            "work\tNOUN\n",
            ".\tPUNCT\n",
            "She\tPRON\n",
            "has\tVERB\n",
            "a\tDET\n",
            "shower\tNOUN\n",
            "and\tCCONJ\n",
            "gets\tVERB\n",
            "dressed\tVERB\n",
            ".\tPUNCT\n",
            "She\tPRON\n",
            "wears\tVERB\n",
            "a\tDET\n",
            "uniform\tNOUN\n",
            ".\tPUNCT\n",
            "At\tADP\n",
            "4.30\tNUM\n",
            ",\tPUNCT\n",
            "Carole\tPROPN\n",
            "has\tVERB\n",
            "cereal\tNOUN\n",
            "with\tADP\n",
            "milk\tNOUN\n",
            "and\tCCONJ\n",
            "drinks\tVERB\n",
            "a\tDET\n",
            "large\tADJ\n",
            "coffee\tNOUN\n",
            ".\tPUNCT\n",
            "After\tADP\n",
            "that\tPRON\n",
            ",\tPUNCT\n",
            "she\tPRON\n",
            "packs\tVERB\n",
            "her\tPRON\n",
            "flight\tNOUN\n",
            "bag\tNOUN\n",
            "for\tADP\n",
            "the\tDET\n",
            "day\tNOUN\n",
            ".\tPUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 4.** Напишите функцию, которая принимает **список токенов** в качестве аргумента и возвращает отфильтрованный список токенов, из которого удалены стоп-слова. При решении используйте библиотеку spacy.\n",
        "\n",
        "**Задача 4.1.** Добавьте в функцию параметр `additional_filter`, который будет содержать список слов, которые также нужно исключить из исходного списка токенов (если список пустой, то дополнительно ничего исключаться не будет).\n",
        "\n",
        "**Задача 4.2.** Добавьте в функцию параметр  `filter_numbers` булевого типа данных, который:\n",
        "\n",
        "\n",
        "*   при значении True отфильтрует список токенов таким образом, чтобы из него также были удалены такие токены, в которых есть хотя бы одна цифра;\n",
        "*   при значении False не будет дополнительно фильтровать токены по критерию наличия цифры.\n",
        "\n",
        "**Задача 4.3.** Добавьте в функцию параметр `filter_named_entities` булевого типа данных, который:\n",
        "\n",
        "*   при значении True отфильтрует список токенов таким образом, чтобы из него также были удалены именованные сущности;\n",
        "*   при значении False не будет дополнительно фильтровать токены.\n",
        "\n",
        "При решении задачи учтите, что библиотека spacy может разбивать текст на токены по-разному при обычном разбиении и при выявлении именованных сущностей (например, именованной сущностью может являться словосочетание \"earier this week\").\n",
        "\n",
        "\n",
        "Перед решением задачи может быть полезно ознакомиться с такими методами работы со строками, как find(), replace() и др."
      ],
      "metadata": {
        "id": "Ew5ZkttGWjK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def filter_tokens(tokens, additional_filter=None):\n",
        "    additional_filter = set(word.lower() for word in (additional_filter or []))\n",
        "    return [token.text for token in nlp(\" \".join(tokens))\n",
        "            if not token.is_stop and token.text.lower() not in additional_filter]\n",
        "\n",
        "text = \"Carole is an aeroplane pilot.\"\n",
        "tokens = text.split()\n",
        "additional_filter = []\n",
        "\n",
        "filtered = filter_tokens(tokens, additional_filter)\n",
        "print(filtered)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yorlpBvI6Z04",
        "outputId": "3a0fb468-2ced-489e-d147-915388fc1ddc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Carole', 'aeroplane', 'pilot', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 5.** Протестируйте работу функций из задач 1-4 (напишите вызовы каждой функции) на примере произвольного текста на английском языке."
      ],
      "metadata": {
        "id": "SAm5PWr0o8Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "10KfPNcZo71K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 6*.** Изучите [статью об автоматическом определении тем в наборе текстов](https://medium.com/data-science/let-us-extract-some-topics-from-text-data-part-i-latent-dirichlet-allocation-lda-e335ee3e5fa4).\n",
        "\n",
        "Напишите программу, которая выявит в наборе текстов N тем (количество тем определите самостоятельно экспериментальным образом). Оцените качество разбиения с помощью метрики `coherence score`.\n",
        "\n",
        "На этапе пре-процессинга можно использовать функции, написанные при решении задач 1-4 или попробовать сделать это с помощью библиотеки NLTK, чтобы изучить альтернативные способы решения задачи.\n",
        "\n",
        "Можно запустить код ниже, чтобы загрузить набор текстов в переменную texts (тип данных – список) и работать с ним. Данный набор текстов представляет собой реальные данные о поисковых запросах в Яндекс.Поиске за определенный период.\n",
        "\n",
        "Либо можно использовать свой набор текстов."
      ],
      "metadata": {
        "id": "_gOGnii0sX7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Код для загрузки данных\n",
        "import pandas as pd\n",
        "import requests\n",
        "from urllib.parse import urlencode\n",
        "\n",
        "# адрес файлов\n",
        "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
        "public_key_data = 'https://disk.yandex.ru/d/E0k1Ko4yExdbVw'\n",
        "\n",
        "# функция для загрузки данных по Yandex Disk API\n",
        "def get_data_from_ya(pk):\n",
        "    url_ab = base_url + urlencode(dict(public_key=pk))\n",
        "    response = requests.get(url_ab)\n",
        "    download_url = response.json()['href']\n",
        "    # загружаем файл в df\n",
        "    download_response = requests.get(download_url)\n",
        "    df_from_yd = pd.read_json(download_url)\n",
        "    return df_from_yd\n",
        "\n",
        "texts = list(get_data_from_ya(public_key_data)['query'].unique())"
      ],
      "metadata": {
        "id": "g2h9WuojHrnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNkrkuG9upaI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}